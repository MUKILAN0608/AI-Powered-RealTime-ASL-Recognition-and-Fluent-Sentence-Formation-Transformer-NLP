# ğŸ›ï¸ BARTâ€‘T5â€‘LLama3â€‘Enhancedâ€‘ASLâ€‘Translationâ€‘withâ€‘Linguisticâ€‘Refinementâ€‘andâ€‘Speechâ€‘Synthesis

An endâ€‘toâ€‘end ASL-to-English system that blends realâ€‘time visual recognition, robust linguistic refinement (spellcheck + grammar + POS agreement), safe sentence formation (local and LLama3â€‘guarded), and natural speech synthesis â€” all wrapped in a clean, professional UI.

## âœ¨ Key Capabilities

- ğŸ–ï¸ Realâ€‘time hand landmark tracking (MediaPipe)
- ğŸ”¤ Letter âœ word formation with temporal stability (debounce/hold detection)
- ğŸ§  Correction pipeline: spellcheck + typoâ€‘aware similarity (Levenshtein, keyboard proximity, repeat tolerance)
- ğŸ§¾ POSâ€‘aware subjectâ€‘verb agreement (I am / he is / we are)
- ğŸ§© Safe sentence formation: local framer or LLama3 (Ollama) strictly for arranging words; words are preserved
- ğŸ”ˆ Background textâ€‘toâ€‘speech (queued) for fluent audio output
- ğŸ§¼ Minimal, distractionâ€‘free UI: predicted word and formed sentence at topâ€‘left

## ğŸ“¦ Requirements

- Python 3.8+
- A webcam
- Model file: `sign_language_model.pkl`

Install dependencies:
```bash
pip install -r requirements.txt
```

Optional: place `frequency_dict.txt` in the project root to expand the spellcheck vocabulary.

## ğŸš€ Quick Start

```bash
python completed.py
```

Controls (kept minimal on screen):
- SPACE: add current word to the sentence
- ENTER: frame and speak the sentence
- BACKSPACE: remove last word
- C: clear sentence
- Q: quit

## ğŸ§­ How It Works

1) Tracking and letters
- Live frames â†’ MediaPipe hands â†’ 21â€‘point landmarks â†’ classifier â†’ letters
- Temporal stability ensures a letter is appended only after it is steady

2) Word correction (preserves intent)
- If a token exists in the spellcheck set, it is kept
- Otherwise we correct using a layered strategy:
  - First/lastâ€‘letterâ€‘aware nearestâ€‘word search (Levenshtein + keyboardâ€‘typo similarity)
  - Repeatedâ€‘letter tolerance (cooool â†’ cool)
  - Fallback to curated dictionaries (advanced/common)
  - Examples: kikl â†’ kill, fkee â†’ free, bild â†’ build, hapyy â†’ happy

3) Sentence formation (no hallucination)
- Words are framed into a sentence; we enforce subjectâ€‘verb agreement (toâ€‘be: am/is/are) and punctuation
- Ollama can be used to arrange words more naturally, but the system verifies that ALL corrected words are preserved; if not, it falls back to local framing

4) Output
- The predicted word and the current sentence are rendered in the topâ€‘left
- The final sentence is spoken via TTS

## âš™ï¸ Configuration Highlights

- Camera: 1920Ã—1080, 30 FPS (defaults in code)
- Recognition stability: ~2 seconds hold per letter (tunable)
- Spellcheck sources: `frequency_dict.txt`, validator common words, correction dictionaries
- Window title: â€œSign Language Recognitionâ€

## ğŸ§© Detailed NLP/Linguistics Pipeline

- Token acceptance policy: keep exact tokens that already exist in the spellcheck set
- Unknown tokens: correct via combined score = Levenshtein + keyboard proximity + repeat collapse, with first/last letter preference and length windowing
- POS layer: spaCyâ€‘based agreement pass for toâ€‘be verbs (am/is/are) and capitalization of â€œIâ€
- Sentence formation safety: LLama3 is promptâ€‘constrained to arrange words, not invent them; output is rejected if any corrected word is missing, then local framing is applied

## ğŸ§ª Examples

- Input letters: B I L L â†’ word â€œBILLâ€ â†’ correction â€œbuildâ€ (dictionary and similarity)
- Input: â€œi are happyâ€ â†’ agreement â†’ â€œI am happy.â€
- Input noisy token â€œfkeeâ€ â†’ corrected to â€œfreeâ€ â†’ included verb phrase becomes â€œI am free.â€ when framed

## ğŸ› ï¸ Troubleshooting

- Camera not available: close other apps using the webcam; check permissions
- Model missing: ensure `sign_language_model.pkl` is in the project root
- TTS issues: verify system audio; try a different voice/rate in code if needed
- Corrections feel off: add domain terms to `frequency_dict.txt` to bias the spellcheck

## ğŸ“ Repository Layout (excerpt)

```
completed.py            # Main application
requirements*.txt       # Dependency lists
sign_language_model.pkl # Trained classifier (required)
frequency_dict.txt      # Optional spell list for correction
logs/recognition.log    # Runtime log
```

## ğŸ“„ License

MIT License. See LICENSE for details.

## ğŸ™ Acknowledgments

- MediaPipe Hands for landmark detection
- Community NLP resources for spellchecking and agreement cues

---

For best results, ensure good lighting and keep hands within the camera frame. The application will display the predicted word and the evolving sentence at the topâ€‘left while speaking the finalized sentence.
